<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>StarCroce</title>
 <link href="http://starcroce.github.io/" rel="self"/>
 <link href="http://starcroce.github.io"/>
 <updated>2014-10-28T16:26:02-07:00</updated>
 <id>http://starcroce.github.io</id>
 <author>
   <name>Yisha Wu</name>
   <email>wuyisha@gmail.com</email>
 </author>

 
 <entry>
   <title>Relase Note</title>
   <link href="http://starcroce.github.io/tech/2014/10/28/relase-note"/>
   <updated>2014-10-28T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/tech/2014/10/28/relase-note</id>
   <content type="html">
&lt;p&gt;Just to take some notes about 1st release parameters.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;max_df: 0.2&lt;/li&gt;
  &lt;li&gt;n_gram: (1, 2)&lt;/li&gt;
  &lt;li&gt;tokenizer: StemTokenizer()&lt;/li&gt;
  &lt;li&gt;stop_words: ‘english’&lt;/li&gt;
  &lt;li&gt;C: 1.0&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Preprocess:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;normalization&lt;/li&gt;
  &lt;li&gt;convert to lower&lt;/li&gt;
  &lt;li&gt;remove punctuation&lt;/li&gt;
  &lt;li&gt;stem&lt;/li&gt;
  &lt;li&gt;remove stopwords&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All the previous may be changed according to the updated data set. And the service code needs to be modified according to the updated training result.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Data Mining Result Analysis</title>
   <link href="http://starcroce.github.io/tech/2014/10/16/data-mining-result-analysis"/>
   <updated>2014-10-16T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/tech/2014/10/16/data-mining-result-analysis</id>
   <content type="html">
&lt;p&gt;Just want to take some notes about how to analysis the classificaiton results.&lt;/p&gt;

&lt;h3 id=&quot;confusion-matrix&quot;&gt;Confusion Matrix:&lt;/h3&gt;

&lt;p&gt;TP / FP / FN / TN:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;True Positive&lt;/strong&gt;: category A classified as category A.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;False Positive&lt;/strong&gt;: category B classified as category A.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;False Negative&lt;/strong&gt;: category A classified as category B.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;True Negative&lt;/strong&gt;: category B classified as category B.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The confusion matrix looks like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.gepsoft.com/gepsoft/APS3KB/Chapter09/Section2/confusionmatrix.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is another confusion matrix that exchange the posisiton of FN and FP. I don’t know which one is better.&lt;/p&gt;

&lt;h3 id=&quot;sensitivity-specificity-and-other&quot;&gt;Sensitivity, Specificity and other&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Parameter&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Value&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;sensititvity (recall, true positive rate)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;TP / (TP + FN)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;false negative rate&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FN / (TP + FN) = 1 - recall&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;specificity (true negative rate)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;TN / (FP + TN)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;fall-out (false positive rate)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FP / (FP + TN) = 1 - spec&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;positive predication value (precision)&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;TP / (TP + FP)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;false discovery rate&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FP / (FP + TP) = 1 - ppv&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;negative prediction value&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;TN / (TN + FN)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;false omission rate&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;FN / (FN + TN)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;accuracy&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;(TP + TN) / ALL&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;f1 score&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2 * TP / (2 * TP + FP + FN) = 2 * precision * recall / (precision + recall)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;All the above info can be found in this &lt;a href=&quot;http://en.wikipedia.org/wiki/Confusion_matrix&quot;&gt;wiki page&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;receiver-operating-characteristic&quot;&gt;Receiver Operating Characteristic&lt;/h3&gt;

&lt;p&gt;Use x = FPR and y = TPR, we can draw a point in a space from (0, 0) to (1, 1). The best position for a classifier is at top left point (0, 1), which means zero FPR and zero FNR. And the result of a random classifier will be at the line from (0, 0) to (1, 1), which is the &lt;em&gt;line of no-discrimination&lt;/em&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Architecture of My Project</title>
   <link href="http://starcroce.github.io/tech/2014/10/12/architecture-of-my-project"/>
   <updated>2014-10-12T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/tech/2014/10/12/architecture-of-my-project</id>
   <content type="html">
&lt;p&gt;Just want to take some high level notes about my project architecture. No tech details, no code.&lt;/p&gt;

&lt;h1 id=&quot;service&quot;&gt;Service&lt;/h1&gt;

&lt;h2 id=&quot;client&quot;&gt;Client&lt;/h2&gt;

&lt;p&gt;PHP code, input is the raw social post extracted from our Chrome extensioin. It will send this data to the NLP server via socket and wait for the result.&lt;/p&gt;

&lt;h2 id=&quot;server&quot;&gt;Server&lt;/h2&gt;

&lt;p&gt;Main thread is listening on &lt;strong&gt;WORK_PORT&lt;/strong&gt; and waiting for the input data. It will create a new thread to handle the input request when received the new data.&lt;/p&gt;

&lt;p&gt;For the processing part, there are two steps: preprocessing and classification.&lt;/p&gt;

&lt;h3 id=&quot;preprocessing&quot;&gt;Preprocessing&lt;/h3&gt;

&lt;p&gt;I have already talked something about the preprocessing. Basically there are three steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Normalization&lt;/li&gt;
  &lt;li&gt;Tokenize&lt;/li&gt;
  &lt;li&gt;Lemmatization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The details can be found in the &lt;a href=&quot;http://starcroce.github.io/tech/2014/10/07/text-sentiment-analysis/&quot;&gt;previous blog&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;classification&quot;&gt;Classification&lt;/h3&gt;

&lt;p&gt;Load the binay file of classifier and some other objects, read the preprocessed input, classify it.&lt;/p&gt;

&lt;p&gt;Well, seems very simple, ah? Just like Howard Wolowitz said:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;how to fly an airplane: get in the airplane, know where you want to go and fly it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Come on…&lt;/p&gt;

&lt;h1 id=&quot;binary-object&quot;&gt;Binary Object&lt;/h1&gt;

&lt;p&gt;Since I have told my manager that our online service don’t need any third party library, I have to save all the objects depending on NLTK or sklearn as a binary file.&lt;/p&gt;

&lt;p&gt;Basically what we need are the following objects:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Classifier&lt;/li&gt;
  &lt;li&gt;Lemmatization tokenizer&lt;/li&gt;
  &lt;li&gt;Target result (not sure if we must need that)&lt;/li&gt;
  &lt;li&gt;The current training result shows that removing stopwords may decrease the accuracy&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;file-issue&quot;&gt;File Issue&lt;/h1&gt;

&lt;p&gt;When I am trying to load the training set in my local machine, it will always run into some problem. But it works fine if I run it on the server. The result may be the &lt;code&gt;.DS_Store&lt;/code&gt; file created by Mac.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;parameters-updates&quot;&gt;Parameters (updates)&lt;/h1&gt;

&lt;p&gt;LinearSVM, SVM, Naive Bayes (sklearn, nltk), SGDClassifier,&lt;/p&gt;

&lt;p&gt;max_df: 0.0 - 1.0&lt;/p&gt;

&lt;p&gt;stopwords: none, english&lt;/p&gt;

&lt;p&gt;max_feature: none, 5000, 10000, 50000&lt;/p&gt;

&lt;p&gt;ngram: 1, 2, 3&lt;/p&gt;

&lt;p&gt;sublinear_tf: true, false&lt;/p&gt;

&lt;p&gt;tokenizer: stem, lemma, other&lt;/p&gt;

&lt;p&gt;classifier parameters:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;SVM: C&lt;/li&gt;
  &lt;li&gt;SGDClassifier: alpha, penalty, n_iter&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Catalan Number</title>
   <link href="http://starcroce.github.io/life/2014/10/10/catalan-number"/>
   <updated>2014-10-10T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/life/2014/10/10/catalan-number</id>
   <content type="html">
&lt;p&gt;重刷 LeetCode 的时候碰到了那道 Unique Binary Search Tree，虽然知道答案就是 Catalan Number，但是一直没弄清到底怎么回事，趁着我的程序在 server 上估计还要跑 10 个小时才能出结果，就顺便研究下这个。&lt;/p&gt;

&lt;p&gt;通项公式没什么好说的，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/math/d/1/1/d118d8cea7b639dfd5244fcba65910cf.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;wiki 表示递推公式有两种：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/math/6/2/1/6217b3c99a3243afcd5d8dbd58186822.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/math/8/a/4/8a49332e4a46b3a2c7accec81160f5e3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;鉴于 markdown 不方便写公式，我就不演示推导过程了（数学渣不要找借口！！（逃&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;应用&lt;/h3&gt;

&lt;h4 id=&quot;dyck-word&quot;&gt;Dyck Word&lt;/h4&gt;

&lt;p&gt;Cn 是长度为 2n 的 dyck word 数目。Dyck word 是指一个有 n 个 X 和 n 个 Y 的字符串，所有前缀字符串都要满足 X 的数目大于等于 Y 的数目。比如 &lt;strong&gt;XXXYYXYY&lt;/strong&gt; 就是一个 dyck word。&lt;/p&gt;

&lt;p&gt;看到这里又想起 LeetCode 有一道求所有可能的括号排序 Generate Parentheses，跟 dyck word 一样不过就是前缀串里面左括号要大于等于右括号。以前一直是 DFS 求解的，要是知道这个在面试时候牛逼闪闪的说 不就是 catalan number 么。。。算了 no zuo no die，还是别给自己挖坑了。&lt;/p&gt;

&lt;h4 id=&quot;unique-binary-tree&quot;&gt;Unique Binary Tree&lt;/h4&gt;
&lt;p&gt;Cn 表示 n 个节点组成不同构的 binary tree 或者 2n+1 个节点组成不同构的 full binary tree 的数目。其实这两者是一样的，因为要补满一个 binary tree 我们总需要 n+1 个节点。于是再次从 wiki 盗图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://upload.wikimedia.org/wikipedia/commons/0/01/Catalan_number_binary_tree_example.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;然后这个怎么跟 catalan number 在一起搞基了呢。。我们先拿一个节点当做 root，于是剩下 n-1 个节点，这样左右 subtree 的节点数目就变成了 0: n-1, 1: n-2, …, n-2: 1, n-1: 0。假设由 n 个节点组成的不同结构的 binary tree 数目是 T(n)。于是有：&lt;/p&gt;

&lt;p&gt;T(n) = T(0) * T(n-1) + T(1) * T(n-2) + … + T(n-2) * T(1) + T(n-1) * T(0)&lt;/p&gt;

&lt;p&gt;有木有觉得眼熟啊。。递推公式1啊啊啊。。。 好的问题解决，套公式吧骚年们。。&lt;/p&gt;

&lt;h4 id=&quot;section-1&quot;&gt;多边形划分&lt;/h4&gt;
&lt;p&gt;Cn表示通过连结顶点而将 n+2 边的凸多边形分成三角形的方法个数。解题过程基本跟上面类似，选取一个点出发划成两块，两个各有 x 和 y 条边，x+y=n+2。然后 x: y 的可能性有 2: n, 3: n-1, …, n-1: 3, n: 2。&lt;/p&gt;

&lt;p&gt;显而易见，跟 unique binary tree 一个路数，就不多加解释了。&lt;/p&gt;

&lt;h4 id=&quot;section-2&quot;&gt;其他&lt;/h4&gt;
&lt;p&gt;很多问题可以归到上面两类中，比如入栈出栈，街区对角线等。总的来说我的理解就是如果问题的 solution 的形式是类似 dyck word 的，也就是一个序列，要求任意前缀子序列中元素 A 的数目大于等于元素 B，比如括号配对，入栈出栈顺序，街区行走路线等，就可以用 catalan number。&lt;/p&gt;

&lt;p&gt;另一种就是类似 unique binary tree 的，除了上述两类，还有一个典型题 n 层阶梯切割问题。大概形式就是可以分割成两个子问题相加的形式，然后可以套用递推公式1来解决的。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;代码实现&lt;/h3&gt;
&lt;p&gt;上面提供了通项公式和递推公式，那么在代码实现环节，我个人还是推荐递推公式。原因很简单，通项公式需要用到阶乘，这样的话除非是用 Python 等对大数运算支持的很好的语言，不然像 C++，Java 等都会遇到溢出的问题，哪怕是用 unsigned long long，也会有溢出的时候，除非自己实现无限大的大数运算。&lt;/p&gt;

&lt;p&gt;以下是通项公式和递推公式的 Python 代码实现：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import math

def catalan_number_1(n):
	return math.factorial(2*n) / (math.factorial(n+1) * math.factorial(n))

def catalan_number_2(n):
	res = [1, 1]
	for i in range(2, n+1):
		res.append(0)
		for j in range(0, i):
			res[i] += res[j] * res[i-j-1]
	return res[n]

def main():
	for i in range(0, 10):
		print catalan_number_1(i), catalan_number_2(i)

if __name__ == &#39;__main__&#39;:
	main()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;无视掉第二种丑陋的写法，明白怎么实现就好，话说谁告诉我怎么在 Mou 里面实现语法高亮。。。&lt;/p&gt;

&lt;h3 id=&quot;section-4&quot;&gt;最后&lt;/h3&gt;
&lt;p&gt;其实没什么想说的，吐槽下我的程序在 server 上都跑了40个小时还没好。刚刚问了下老板才知道给我 ec2 instance 是 micro 类型的，坑爹呢这是！！！早知道这样还不如用我自己机子跑呢。。&lt;/p&gt;

&lt;p&gt;完。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Python Encoding in My Project</title>
   <link href="http://starcroce.github.io/tech/2014/10/09/python-encoding-in-my-project"/>
   <updated>2014-10-09T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/tech/2014/10/09/python-encoding-in-my-project</id>
   <content type="html">
&lt;p&gt;Previous raw service log: ascii.&lt;/p&gt;

&lt;p&gt;Preprocess function (“https://www.google.com” -&amp;gt; “URL”, “@Tom” -&amp;gt; “@USERNAME”) works fine for both ascii and utf-8.&lt;/p&gt;

&lt;p&gt;Generate random log for manual label: ascii.&lt;/p&gt;

&lt;p&gt;Write manual label result into mysql database: both can work, can keep ascii.&lt;/p&gt;

&lt;p&gt;Posts in MySQL database: utf-8. MySQL will convert it automatically.&lt;/p&gt;

&lt;p&gt;Query post from MySQL into training file: keep utf-8. The default encoding of &lt;code&gt;sklearn.dataset.load_files()&lt;/code&gt; is utf-8.&lt;/p&gt;

&lt;p&gt;After load training set, it seems can do other preprocessing like tokenzie, stemming, lemmatization, filter stopwords without considering the encoding format. Need to confirm it later.&lt;/p&gt;

&lt;p&gt;Input from future online service: ascii, seems no issue based on previous experiment. Need to check if preprocess function will introduce any issue.&lt;/p&gt;

&lt;p&gt;Test set: if use &lt;code&gt;sklearn.dataset.load_files()&lt;/code&gt;, they should be utf-8 and are already after the preprocessing. If we want to simulate the future online service, it can be any format since the preprocess function doesn’t care about that.&lt;/p&gt;

&lt;p&gt;I am working on the last part of simluating future online service. For now I use UCSC demo data and manual label result of our own socila log as the training set. The test set is the bully related images.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Usage of TF IDF</title>
   <link href="http://starcroce.github.io/tech/2014/10/08/usage-of-tf-idf"/>
   <updated>2014-10-08T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/tech/2014/10/08/usage-of-tf-idf</id>
   <content type="html">
&lt;h3 id=&quot;defination&quot;&gt;Defination&lt;/h3&gt;
&lt;p&gt;TF - IDF is short for &lt;strong&gt;term frequency - inverse document frequency&lt;/strong&gt;. The wiki page can be found here: &lt;a href=&quot;http://en.wikipedia.org/wiki/Tf–idf&quot;&gt;tf - idf&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Term frequency means the raw frequency of a term &lt;em&gt;t&lt;/em&gt; in occurs in a document &lt;em&gt;d&lt;/em&gt;, which can be represented as &lt;em&gt;tf(f, d) = f(t, d)&lt;/em&gt;. &lt;/p&gt;

&lt;p&gt;Inverse document frequency measures whether the term is common or rare across all documents. It is the logarithmically scaled fraction of the documents that contain the word, obtained by &lt;strong&gt;dividing the total number of documents by the number of documents containing the term&lt;/strong&gt;, and then taking the logarithm of that quotient, which can be represented as &lt;em&gt;idf(t, D) = log(N / {d in D: t in d})&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Finally &lt;em&gt;tfidf(t, d, D) = tf(t, d) x idf(t, D)&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;usage&quot;&gt;Usage&lt;/h3&gt;
&lt;p&gt;Apparently, if a term &lt;em&gt;t&lt;/em&gt; has a very high &lt;em&gt;tf&lt;/em&gt; in one document, it means that this term appears lots of times in that document. Then we can believe that this term can help us classify this document.&lt;/p&gt;

&lt;p&gt;If the number of documents containing term &lt;em&gt;t&lt;/em&gt; is very small, the &lt;em&gt;idf&lt;/em&gt; will be larger. Then we can also believe that the term &lt;em&gt;t&lt;/em&gt; can help us classify this kind of documents. And idf can help us find some common words like “a”, “the”, “is”. These words can be appeared many times in a document, so the tf value will be very large. But they are also existed in every document, so the idf value will be very small, even 0. Then the tf-idf can help us filter these words.&lt;/p&gt;

&lt;h3 id=&quot;disadvantage&quot;&gt;Disadvantage&lt;/h3&gt;
&lt;p&gt;A basic assumption of tf-idf is that the most meaningful word that help us classify the document should appear most times. However, it is not always correct. A better way is to introduce semantic analysis. A recent way is to use LDA (Latent Dirichlet Allocation). I haven’t use this in my experiment, but I will try to talk a little about that in the next section.&lt;/p&gt;

&lt;h3 id=&quot;lda&quot;&gt;LDA&lt;/h3&gt;
&lt;p&gt;LDA is short for Latent Dirichlet Allocation. Here is a very good explanation about LDA on Quora if you don’t want to read the boring wiki page:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation&quot;&gt;http://www.quora.com/What-is-a-good-explanation-of-Latent-Dirichlet-Allocation&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Basically, LDA is an unsupervised learning algorithm. It can provide the topics that each document contains. If given 3 documents and 2 topics, LDA can return something like “document A is 100% topic 1, document B is 100% topic 2, document C is 80% topic 1 and 20% topic 2”.&lt;/p&gt;

&lt;p&gt;LDA assumes that documents are mixtures of topics. In this model, LDA assumes that documents are created in the following steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Decide how many words that a document have.&lt;/li&gt;
  &lt;li&gt;Choose a topic mixture for the document. For example, we have two topics “food” and “animal”, and we decide to create a document with 30% “food” and 70% “animal”.&lt;/li&gt;
  &lt;li&gt;Pick a topic. So we have 30% probability to pick “food” and 70% probability to pick “animal”.&lt;/li&gt;
  &lt;li&gt;For each topic we picked, generate a word. For example, “food” may generate “beef” with 40% and “animal” will generate “dog” with 35%.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After that, LDA will try to backtrack from the document to find a set of topics that is most likely to generate this document.&lt;/p&gt;

&lt;p&gt;This is just a simple example about how LDA works. I will explain it after I try it in my experiment and read more documents.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Text Sentiment Analysis</title>
   <link href="http://starcroce.github.io/tech/2014/10/07/text-sentiment-analysis"/>
   <updated>2014-10-07T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/tech/2014/10/07/text-sentiment-analysis</id>
   <content type="html">
&lt;h3 id=&quot;attention&quot;&gt;Attention&lt;/h3&gt;
&lt;p&gt;Just for my own memo, not a public tutorial.&lt;/p&gt;

&lt;h3 id=&quot;environment&quot;&gt;Environment&lt;/h3&gt;
&lt;p&gt;Python, NLTK, scikit-learn&lt;/p&gt;

&lt;h3 id=&quot;preprocess&quot;&gt;Preprocess&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;“80% of the data mining work is preprocess”&lt;/em&gt;, cited by Winnie.&lt;/p&gt;

&lt;p&gt;For the raw post from our service, there are serveral preprocessing steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;convert “@abcd” to “@USERNAME”&lt;/li&gt;
  &lt;li&gt;convert “https://www.google.com” to “URL”&lt;/li&gt;
  &lt;li&gt;convert all char to lower case&lt;/li&gt;
  &lt;li&gt;remove punctuations and tokenize&lt;/li&gt;
  &lt;li&gt;stemming or lemmatization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the first three steps, just use regex:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import re
text = re.sub(&#39;@[^\s]+&#39;, &#39;@USERNAME&#39;, text)
text = re.sub(&#39;((www\.[^\s]+)|(https?://[^\s]+))&#39;, &#39;URL&#39;, text)
text.lower()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Actually, the third step can be done at anytime. It makes no difference. Now, these data can be used for third party manual tagging, which is our potential training set.&lt;/p&gt;

&lt;p&gt;For removing the punctuations and tokenziation, we can use RegexTokenizer of NLTK.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from nltk.tokenize import RegexTokenizer
tokenizer = RegenTokenizer(r&#39;\w+&#39;)
tokens = tokenizer.tokenize(text)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It will return a list of tokens without punctuations. But for the tokens, we still need to stem or lemmatize it.&lt;/p&gt;

&lt;p&gt;The basic difference between stemmer and lemmatizer can be found here: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/17317418/stemmers-vs-lemmatizers&quot;&gt;http://stackoverflow.com/questions/17317418/stemmers-vs-lemmatizers&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;NLTK provides some stemmer and lemmatizer like LancasterStemmer and WordNetLemmatizer. For the specific difference, please check NLTK documentation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from nltk.stem.lancaster import LancasterStemmer
from nltk.stem import WordNetLemmatizer
stemmer = LancasterStemmer()
stemmer.stem(&#39;having&#39;)			# become &#39;hav&#39;
lemmatizer = WordNetLemmatizer()
lemmatizer.lemmatize(&#39;dogs&#39;)		# become u&#39;dog&#39;
lemmatizer.lemmatize(&#39;having&#39;, &#39;v&#39;)	# become &#39;have&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Need to test all of these method and choose the best way. I will write a new post about the difference between stemming and lemmatization later.&lt;/p&gt;

&lt;h3 id=&quot;support-vector-machine&quot;&gt;Support Vector Machine&lt;/h3&gt;
&lt;p&gt;scikit-learn provides two implementation of SVM classifier: libsvm and liblinear. The basic difference can be found here: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/11508788/whats-the-difference-between-libsvm-and-liblinear&quot;&gt;http://stackoverflow.com/questions/11508788/whats-the-difference-between-libsvm-and-liblinear&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For linear SVM, there is an important parameter C. The basic infulence can be found here: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel&quot;&gt;http://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;In my experiment, I tried from 1e-2 to 1e5. There are many other parameters in SVC with linear kernel or Linear SVC, but I keep them as the default. &lt;/p&gt;

&lt;p&gt;For the library documentation, we can check &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;The former is libsvm implementation and the latter is liblinear implmentation.&lt;/p&gt;

&lt;p&gt;In scikit-learn, the step of text classification is as follows:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;load the training set&lt;/li&gt;
  &lt;li&gt;count vectorizer&lt;/li&gt;
  &lt;li&gt;tf-idf transformer&lt;/li&gt;
  &lt;li&gt;fit the classifer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And step 2 and 3 can be combined together as tf-idf vectorizer.&lt;/p&gt;

&lt;p&gt;When load the training set, the format of the training file set should be like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;category_1_dir: file1, file2, file3, …&lt;/li&gt;
  &lt;li&gt;category_2_dir: file1, file2, file3, …&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I don’t want to talk about what is tf-idf and how count vectorizer and tf-idf transformer works here. I will write a new blog to specify them in the future.&lt;/p&gt;

&lt;h4 id=&quot;parameter-tuning&quot;&gt;Parameter Tuning&lt;/h4&gt;
&lt;p&gt;Here is a simple example about parameter tuning using scikit-learn: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/&quot;&gt;http://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;There is a class &lt;code&gt;sklearn.grid_search.GridSearchCV&lt;/code&gt; that can help us to find the best parameter combination. The detailed document is here: &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html&quot;&gt;http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;After parameter tuning, we can get the best parameters. Then we can start to train the classifier, save it as the binary file which can be used in the future online service.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hello World</title>
   <link href="http://starcroce.github.io/other/2014/10/07/hello-world"/>
   <updated>2014-10-07T00:00:00-07:00</updated>
   <id>http://starcroce.github.io/other/2014/10/07/hello-world</id>
   <content type="html">
&lt;h3 id=&quot;about-me&quot;&gt;About Me&lt;/h3&gt;

&lt;p&gt;Only for test. Seems cool.&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
